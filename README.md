
ğŸš€ è¿è¡Œä¸å¤ç°
æœ¬é¡¹ç›®ä½¿ç”¨ PyTorch Lightning å’Œ Hydra è¿›è¡Œé…ç½®ç®¡ç†å’Œè®­ç»ƒã€‚

## ç¡¬ä»¶è¦æ±‚
GPU: å¼ºçƒˆæ¨èä½¿ç”¨ NVIDIA GPU è¿›è¡Œè®­ç»ƒã€‚

GPU æ˜¾å­˜ (VRAM): æˆ‘ä»¬çš„æ¨¡å‹ï¼ˆd_model=128, 2å±‚ï¼‰éå¸¸å°ï¼Œåœ¨ batch_size=32 æ—¶ï¼Œ>= 6GB æ˜¾å­˜å³å¯æ»¡è¶³è®­ç»ƒéœ€æ±‚ï¼ˆæ¨è 8GB+ï¼‰ã€‚

ç³»ç»Ÿå†…å­˜ (RAM): >= 16GBï¼ˆç”¨äºåŠ è½½å’Œé¢„å¤„ç† IWSLT 2017 æ•°æ®é›†ï¼‰ã€‚

##  ç¯å¢ƒè®¾ç½®
å…‹éš†æœ¬ä»“åº“ï¼š


```bash

git clone https://github.com/beiahi0/Transformer.git
cd Transformer
```

å®‰è£…æœ¬é¡¹ç›®ç‰¹å®šçš„ä¾èµ–ï¼š

```bash
pip install -r requirements.txt
```
ä¸‹è½½ Spacy è¯­è¨€æ¨¡å‹ï¼ˆç”¨äºåˆ†è¯ï¼‰ï¼š


```bash
python -m spacy download de_core_news_sm
python -m spacy download en_core_web_sm
```
##  å¤ç°è®­ç»ƒ (Training)
æˆ‘ä»¬æ‰€æœ‰çš„å®éªŒå‚æ•°ï¼ˆbatch_size=32, d_model=128, lr=3e-4 ç­‰ï¼‰éƒ½å·²åœ¨ configs/ ç›®å½•ä¸­å®šä¹‰ã€‚config.yaml ä¸­è®¾ç½®çš„éšæœºç§å­ä¸º 42ã€‚

è¦ç²¾ç¡®å¤ç°æˆ‘ä»¬çš„è®­ç»ƒç»“æœï¼ˆçº¦ 60 ä¸ª epochï¼‰ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚è¯¥å‘½ä»¤å°†ï¼š

ä½¿ç”¨ seed=42ã€‚

å¯ç”¨ deterministic=True ä»¥ç¡®ä¿ CUDA ç®—æ³•çš„å¯å¤ç°æ€§ã€‚

è‡ªåŠ¨ä¸‹è½½ IWSLT 2017 æ•°æ®é›†å¹¶æ„å»ºè¯è¡¨ã€‚

ä½¿ç”¨ WandbLogger è®°å½•æ—¥å¿—ï¼ˆè¯·ç¡®ä¿ä½ å·²ç™»å½• wandbï¼‰ã€‚


# è¿è¡Œè®­ç»ƒ
```bash
python src/train.py 
```